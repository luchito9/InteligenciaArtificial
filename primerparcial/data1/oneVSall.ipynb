{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39986,"status":"ok","timestamp":1712633324173,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"},"user_tz":240},"id":"clyp4NcQycWP","outputId":"0b929e92-5fa1-4e5f-d19d-cd5a967a71ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20Q29kX8SxgJ"},"outputs":[],"source":["# utilizado para la manipulación de directorios y rutas\n","import os\n","\n","# Cálculo científico y vectorial para python\n","import numpy as np\n","\n","# Libreria para graficos\n","from matplotlib import pyplot\n","\n","# Modulo de optimizacion en scipy\n","from scipy import optimize\n","\n","# modulo para cargar archivos en formato MATLAB\n","# from scipy.io import loadmat\n","\n","# le dice a matplotlib que incruste gráficos en el cuaderno\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhRjL2ptSxgK","executionInfo":{"status":"ok","timestamp":1712634194028,"user_tz":240,"elapsed":423,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"a6425bf4-5ff4-4a7b-dc16-4f815d835b10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño de datos de entrenamiento para X: (46876, 55)\n","Tamaño de datos de entrenamiento para y: (46876,)\n","Tamaño de datos de prueba para X: (11720, 55)\n","Tamaño de datos de prueba para y: (11720,)\n"]}],"source":["import numpy as np\n","\n","#usare Scikit-learn es una de las bibliotecas más populares para el aprendizaje automático en Python. La función train_test_split se utiliza\n","#para dividir un conjunto de datos en dos subconjuntos: uno para entrenamiento y otro para pruebas\n","from sklearn.model_selection import train_test_split\n","\n","\n","# La entrada es de 784 representando mis variables X\n","input_layer_size  = 56\n","\n","# 10 etiquetas, de 1 a 10 (tomar en cuenta que se asigna \"0\" a la etiqueta 10)\n","num_labels = 2\n","\n","#cargo mi dataset entrenar y para evaluar algoritmos de reconocimiento de digitos escritos a mano\n","data = np.loadtxt('/content/drive/MyDrive/primelParcial/preparado_1.txt', delimiter=';')\n","\n","# Dividir los datos en características (X) y etiquetas (y)\n","X = data[:, 1:]\n","y = data[:, 55]\n","m = y.size\n","\n","\n","\n","# declarando mis variables para mi division de (80% para entrenamiento, 20% para pruebas)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","#imprimo mi 80% de datos de entrenamiento de mi dataset tanto mis variables x mi y\n","print(\"Tamaño de datos de entrenamiento para X:\", X_train.shape)\n","print(\"Tamaño de datos de entrenamiento para y:\", y_train.shape)\n","\n","\n","#imprimo mi 20% de datos para la prueba de mi dataset tanto mis variables x mi y\n","print(\"Tamaño de datos de prueba para X:\", X_test.shape)\n","print(\"Tamaño de datos de prueba para y:\", y_test.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1712634310410,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"},"user_tz":240},"id":"7EIAVi-1I91N","outputId":"ed8f7f45-8a38-42b5-cd0f-eb2beac48697"},"outputs":[{"output_type":"stream","name":"stdout","text":["(58596, 56)\n","[0. 0. 0. ... 1. 1. 1.]\n"]}],"source":["print(data.shape)\n","print(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459,"status":"ok","timestamp":1712634353004,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"},"user_tz":240},"id":"HWF5C5Jt8wNb","outputId":"5d279bc6-77fb-4b31-c7da-035badb20a62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño de datos de entrenamiento normalizados para X: (46876, 55)\n","Tamaño de datos de prueba normalizados para X: (11720, 55)\n"]}],"source":["#haora normalizo mis los valores de mis X  para asegurarme que esten en una misma escala\n","# tanto los de prueba como los de entrenamiento\n","def featureNormalize(X_train, X_test):\n","    mu = np.mean(X_train, axis=0)\n","    sigma = np.std(X_train, axis=0)\n","\n","    # agrego este sigma el caso de desviación estándar cero por si hay division entre 0\n","    sigma[sigma == 0] = 1e-8\n","\n","    #aplico normalizacion\n","    X_train_normalized = (X_train - mu) / sigma\n","    X_test_normalized = (X_test - mu) / sigma\n","\n","    return X_train_normalized, X_test_normalized, mu, sigma\n","\n","#llamo a mi  función para normalizar los datos\n","X_train_normalized, X_test_normalized, mu, sigma = featureNormalize(X_train, X_test)\n","\n","# Imprimo el tamaño de los conjuntos de entrenamiento y prueba normalizados\n","print(\"Tamaño de datos de entrenamiento normalizados para X:\", X_train_normalized.shape)\n","print(\"Tamaño de datos de prueba normalizados para X:\", X_test_normalized.shape)\n","\n"]},{"cell_type":"code","source":["# asigno a una varaible nueva pasandole las variables normalizadas y las columnas\n","m_train, n_train = X_train_normalized.shape\n","m_test, n_test = X_test_normalized.shape\n","\n","X_train_norm = X_train_normalized\n","X_test_norm =X_test_normalized\n"],"metadata":{"id":"UT3Uk5OPcWrt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Conjunto de entrenamiento normalizado:\")\n","print(X_train_norm)\n","print(\"Conjunto de prueba normalizado:\")\n","print(X_test_norm)\n"],"metadata":{"id":"r9e6MRrW1G22","executionInfo":{"status":"ok","timestamp":1712634362491,"user_tz":240,"elapsed":935,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"45cf7469-b65e-48ce-dcb2-8274cdda4662"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Conjunto de entrenamiento normalizado:\n","[[ 0.48678508 -0.7469441   0.         ... -0.02958739  0.01222098\n","   1.00299108]\n"," [ 0.86357108  2.05508743  0.         ... -0.02958739  0.01222098\n","   1.00299108]\n"," [-1.39714495 -0.35122079  0.         ... -0.02958739  0.01222098\n","  -0.99701784]\n"," ...\n"," [-1.02035895 -0.35484754  0.         ... -0.02958739  0.01222098\n","  -0.99701784]\n"," [ 1.9939291  -0.39987201  0.         ... -0.02958739  0.01222098\n","  -0.99701784]\n"," [ 0.48678508  2.23063318  0.         ... -0.02958739  0.01222098\n","   1.00299108]]\n","Conjunto de prueba normalizado:\n","[[ 0.10999907 -0.44158365  0.         ... -0.02958739  0.01222098\n","   1.00299108]\n"," [-1.02035895 -0.34227028  0.         ... -0.02958739  0.01222098\n","  -0.99701784]\n"," [ 0.48678508 -0.43109445  0.         ... -0.02958739  0.01222098\n","   1.00299108]\n"," ...\n"," [ 0.86357108  2.2130451   0.         ... -0.02958739  0.01222098\n","   1.00299108]\n"," [ 0.48678508  2.09796883  0.         ... -0.02958739  0.01222098\n","   1.00299108]\n"," [ 0.48678508 -0.74694436  0.         ... -0.02958739  0.01222098\n","   1.00299108]]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5marXeKSxgM"},"outputs":[],"source":["# Selecciona aleatoriamente 100 puntos de datos para mostrar\n","# y la guardare el sel\n","rand_indices = np.random.choice(m, 100, replace=False)\n","sel = X[rand_indices, :]\n","\n","# displayData(sel)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sB9Kyi8SxgN"},"outputs":[],"source":["# usare la sigmoide ´para  tomar un valor real como entrada y produce un valor en el rango de 0 a 1 como salida\n","def sigmoid(z):\n","\n","    return 1.0 / (1.0 + np.exp(-z))"]},{"cell_type":"code","source":["#Usare una función de costo y su gradiente para un problema de regresión logística regularizada.\n","#para encontrar los parámetros theta que minimizan la función de costo.\n","\n","def lrCostFunction(theta, X, y, lambda_):\n","\n","    m = y.size\n","\n","    # convierte las etiquetas a valores enteros si son boleanos\n","    if y.dtype == bool:\n","        y = y.astype(int)\n","\n","    J = 0\n","    grad = np.zeros(theta.shape)\n","\n","    h = sigmoid(X.dot(theta.T))\n","\n","    temp = theta\n","    temp[0] = 0\n","\n","#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n","    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","\n","    grad = (1 / m) * (h - y).dot(X)\n","#     theta = theta - (alpha / m) * (h - y).dot(X)\n","    grad = grad + (lambda_ / m) * temp\n","\n","    return J, grad\n","#    return J, theta"],"metadata":{"id":"xUtIa6eauTfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# un ejemplo de calculo del costo\n","theta_initial = np.zeros(X_train_normalized.shape[1])\n","\n","# Definir el valor de lambda\n","lambda_ = 0.1\n","\n","# Calcular el costo y el gradiente utilizando la función de costo\n","costo, _ = lrCostFunction(theta_initial, X_train_normalized, y_train, lambda_)\n","\n","print(\"Costo de entrenamiento:\", costo)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcZCsvuVvIsV","executionInfo":{"status":"ok","timestamp":1712634373245,"user_tz":240,"elapsed":427,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"21249f49-cd94-4d5b-df33-2e339c041edb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Costo de entrenamiento: 0.6931471805599467\n"]}]},{"cell_type":"code","source":["#usare scipy  para utilizar sus funcionalidades de optimización numérica en Python.\n","#entrenare con  \"One-vs-All\",para que me devuelba loss parámetros óptimos del modelo para cada clase.\n","from scipy import optimize\n","\n","def oneVsAll(X, y, num_labels, lambda_):\n","    # Algunas variables útiles\n","    m, n = X.shape\n","\n","    # Inicializar matriz de parámetros theta\n","    all_theta = np.zeros((num_labels, n + 1))\n","\n","    # Agregar una columna de unos a la matriz X\n","    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","\n","    # Optimizar los parámetros theta para cada clase\n","    for c in range(num_labels):\n","        initial_theta = np.zeros(n + 1)\n","        options = {'maxiter': 50}  # Opciones para el optimizador\n","        # Minimizar la función de costo regularizada utilizando el método de conjugado de gradiente\n","        res = optimize.minimize(lrCostFunction, initial_theta, (X, (y == c), lambda_), jac=True, method='CG', options=options)\n","        # Asignar los parámetros theta óptimos a la fila correspondiente en all_theta\n","        all_theta[c] = res.x\n","\n","    return all_theta\n"],"metadata":{"id":"ESFGf8QmvhrN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#entreno un clasificador usando uno vs todos e imprimo mis valores de mis clases\n","\n","lambda_ = 0.1\n","all_theta = oneVsAll(X, y, num_labels, lambda_)\n","print(all_theta.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h07m4RqrwkXY","executionInfo":{"status":"ok","timestamp":1712634384962,"user_tz":240,"elapsed":6442,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"2d526985-eaa3-40d6-d9f1-19bd3f9497f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n"]},{"output_type":"stream","name":"stdout","text":["(10, 56)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-26-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-27-0fae340bc49a>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjFoFe1bSxgO"},"outputs":[],"source":["#tomare los valores óptimos del modelo (all_theta) y un conjunto de datos de entrada (X), y\n","#predice las etiquetas de clase para cada muestra en X utilizando el enfoque de \"One-vs-All\" en la regresión logística\n","\n","def predictOneVsAll(all_theta, X):\n","\n","    m = X.shape[0];\n","    num_labels = all_theta.shape[0]\n","\n","    p = np.zeros(m)\n","\n","    # Add ones to the X data matrix\n","    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n","\n","    return p"]},{"cell_type":"code","source":["# Usando mi 20% de datos de prueba\n","print(X_test_norm.shape)\n","\n","# realizare  predicciones en el conjunto de prueba usando el 20%\n","pred_test = predictOneVsAll(all_theta, X_test_norm)\n","\n","#  la precisión en el conjunto de prueba usando mi 20% de y   de prueba\n","accuracy_test = np.mean(pred_test == y_test) * 100\n","\n","# Imprimir la precisión del conjunto de prueba\n","print('Precisión en el conjunto de prueba: {:.2f}%'.format(accuracy_test))\n","\n","# al igual que el ejemplo del ing seleccionare un subconjunto de datos de prueba para mostrar un ejemplo\n","X_prueba_subconjunto = X_test_norm[10:150, :]\n","y_prueba_subconjunto = y_test[10:150]\n","\n","# hoara agregare una columna de unos a la matriz X_prueba_subconjunto para realizar mis prediccion\n","X_prueba_subconjunto = np.concatenate([np.ones((X_prueba_subconjunto.shape[0], 1)), X_prueba_subconjunto], axis=1)\n","\n","# realizando las predicciones en el subconjunto de datos de prueba\n","pred_prueba_subconjunto = np.argmax(sigmoid(X_prueba_subconjunto.dot(all_theta.T)), axis=1)\n","\n","# Imprimo las predicciones y las etiquetas del mis 20% de datos de prueba aver si sale bien :V\n","print(\"Predicciones del subconjunto de datos de prueba:\")\n","print(pred_prueba_subconjunto)\n","print(\"Etiquetas reales del subconjunto de datos de prueba:\")\n","print(y_prueba_subconjunto)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKROnowsyyyU","executionInfo":{"status":"ok","timestamp":1712634709529,"user_tz":240,"elapsed":621,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"a2e043f6-8a07-4d42-dd15-0f299b85bdae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(11720, 55)\n","Precisión en el conjunto de prueba: 42.72%\n","Predicciones del subconjunto de datos de prueba:\n","[0 1 0 1 2 2 1 2 2 2 2 0 2 0 0 2 0 1 1 0 1 1 0 0 2 2 0 2 0 0 2 1 1 2 2 1 2\n"," 2 2 0 0 1 2 1 0 0 2 0 2 2 2 2 2 0 0 1 2 1 2 1 2 0 1 2 2 0 0 2 2 0 1 2 2 1\n"," 1 2 1 1 2 0 1 0 2 0 1 2 2 1 1 2 0 2 0 0 1 2 2 2 2 2 0 2 1 0 2 2 1 2 1 0 1\n"," 2 1 1 2 1 2 1 1 1 2 2 1 0 2 0 2 2 0 0 2 1 2 1 1 0 0 2 2 2]\n","Etiquetas reales del subconjunto de datos de prueba:\n","[0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0.\n"," 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n"," 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n"," 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n"," 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n"," 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n"]}]},{"cell_type":"markdown","source":["¡Claro! La técnica One-vs-All (también conocida como One-vs-Rest) es una técnica de clasificación que se puede aplicar tanto a problemas de clasificación binaria como a problemas de clasificación multiclase.\n","\n","En un problema de clasificación binaria, como el que tienes (por ejemplo, determinar si un dato tiene o no tiene malware), la técnica One-vs-All aún puede ser utilizada. La idea es entrenar múltiples clasificadores binarios, donde cada clasificador intenta distinguir una clase específica de las otras.\n","\n","En tu caso, dado que tienes un problema binario (malware o no malware), solo necesitas un clasificador. Sin embargo, la técnica One-vs-All sigue siendo aplicable conceptualmente. Puedes pensar en ello como entrenar un clasificador que distingue \"malware\" de \"no malware\" (es decir, un clasificador que busca la clase \"1\" frente a la clase \"0\"), lo que esencialmente es un problema de clasificación binaria.\n","\n","Por lo tanto, aunque en la práctica solo estás resolviendo un problema de clasificación binaria, puedes utilizar la técnica One-vs-All para conceptualmente encapsularlo y aplicarla de manera coherente en la implementación.\n","\n","Espero que esto aclare por qué se puede aplicar la técnica One-vs-All en un problema de clasificación binaria como el tuyo. Si tienes alguna otra pregunta o necesitas más aclaraciones, no dudes en preguntar."],"metadata":{"id":"iCVQwNXG-kkA"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}