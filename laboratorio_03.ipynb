{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43721,"status":"ok","timestamp":1710878152135,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"},"user_tz":240},"id":"clyp4NcQycWP","outputId":"b221f840-2ba7-4f31-a947-70478e0517bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20Q29kX8SxgJ"},"outputs":[],"source":["# utilizado para la manipulación de directorios y rutas\n","import os\n","\n","# Cálculo científico y vectorial para python\n","import numpy as np\n","\n","# Libreria para graficos\n","from matplotlib import pyplot\n","\n","# Modulo de optimizacion en scipy\n","from scipy import optimize\n","\n","# modulo para cargar archivos en formato MATLAB\n","# from scipy.io import loadmat\n","\n","# le dice a matplotlib que incruste gráficos en el cuaderno\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhRjL2ptSxgK","executionInfo":{"status":"ok","timestamp":1710770372697,"user_tz":240,"elapsed":10143,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"e471b099-4a6e-48a2-dc94-974b64ee317e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño de datos de entrenamiento para X: (168000, 784)\n","Tamaño de datos de entrenamiento para y: (168000,)\n","Tamaño de datos de prueba para X: (42000, 784)\n","Tamaño de datos de prueba para y: (42000,)\n"]}],"source":["import numpy as np\n","\n","#usare Scikit-learn es una de las bibliotecas más populares para el aprendizaje automático en Python. La función train_test_split se utiliza\n","#para dividir un conjunto de datos en dos subconjuntos: uno para entrenamiento y otro para pruebas\n","from sklearn.model_selection import train_test_split\n","\n","\n","# La entrada es de 784 representando mis variables X\n","input_layer_size  = 784\n","\n","# 10 etiquetas, de 1 a 10 (tomar en cuenta que se asigna \"0\" a la etiqueta 10)\n","num_labels = 10\n","\n","#cargo mi dataset entrenar y para evaluar algoritmos de reconocimiento de digitos escritos a mano\n","data = np.loadtxt('/content/drive/MyDrive/laboratorio3/DigitRecognizer_extended_trainData_preP.csv', delimiter=';')\n","\n","# Dividir los datos en características (X) y etiquetas (y)\n","X = data[:, 1:]\n","y = data[:, 0]\n","m = y.size\n","\n","\n","\n","# declarando mis variables para mi division de (80% para entrenamiento, 20% para pruebas)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","#imprimo mi 80% de datos de entrenamiento de mi dataset tanto mis variables x mi y\n","print(\"Tamaño de datos de entrenamiento para X:\", X_train.shape)\n","print(\"Tamaño de datos de entrenamiento para y:\", y_train.shape)\n","\n","\n","#imprimo mi 20% de datos para la prueba de mi dataset tanto mis variables x mi y\n","print(\"Tamaño de datos de prueba para X:\", X_test.shape)\n","print(\"Tamaño de datos de prueba para y:\", y_test.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1710770372697,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"},"user_tz":240},"id":"7EIAVi-1I91N","outputId":"958d8499-5106-412a-b9ce-1fd342a20c91"},"outputs":[{"output_type":"stream","name":"stdout","text":["(210000, 785)\n"]}],"source":["print(data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1710770372698,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"},"user_tz":240},"id":"aw2yVc8ESxgL","outputId":"6f59842e-fa8f-4098-8e5d-91d9053a395d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0. 188. 255.  94.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0. 191. 250. 253.  93.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0. 123. 248. 253. 167.  10.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.  80. 247. 253. 208.  13.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","  29. 207. 253. 235.  77.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54.\n"," 209. 253. 253.  88.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  93. 254.\n"," 253. 238. 170.  17.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  23. 210. 254.\n"," 253. 159.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 209. 253. 254.\n"," 240.  81.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  27.  23. 253. 254.\n","  13.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.  20. 206. 254. 253. 198.\n","   7.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0. 168. 253. 253. 196. 254.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.  20. 203. 253. 248.  76.   0.\n","   7.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.  22. 188. 253. 245.  93.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0. 103. 253. 253. 191.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.  89. 240. 253. 195.  25.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.  15. 220. 253. 253.  80.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.  94. 253. 253. 253.  94.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.  89. 251. 253. 250. 131.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0. 214. 218.  95.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n","   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n","[1. 0. 1. ... 9. 9. 9.]\n"]}],"source":["print(X[0,:])\n","print(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1056,"status":"ok","timestamp":1710770373716,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"},"user_tz":240},"id":"HWF5C5Jt8wNb","outputId":"318f0cce-ecb3-4528-c2a9-2efe59f5e5e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño de datos de entrenamiento normalizados para X: (168000, 784)\n","Tamaño de datos de prueba normalizados para X: (42000, 784)\n"]}],"source":["#haora normalizo mis los valores de mis X  para asegurarme que esten en una misma escala\n","# tanto los de prueba como los de entrenamiento\n","def featureNormalize(X_train, X_test):\n","    mu = np.mean(X_train, axis=0)\n","    sigma = np.std(X_train, axis=0)\n","\n","    # agrego este sigma el caso de desviación estándar cero por si hay division entre 0\n","    sigma[sigma == 0] = 1e-8\n","\n","    #aplico normalizacion\n","    X_train_normalized = (X_train - mu) / sigma\n","    X_test_normalized = (X_test - mu) / sigma\n","\n","    return X_train_normalized, X_test_normalized, mu, sigma\n","\n","#llamo a mi  función para normalizar los datos\n","X_train_normalized, X_test_normalized, mu, sigma = featureNormalize(X_train, X_test)\n","\n","# Imprimo el tamaño de los conjuntos de entrenamiento y prueba normalizados\n","print(\"Tamaño de datos de entrenamiento normalizados para X:\", X_train_normalized.shape)\n","print(\"Tamaño de datos de prueba normalizados para X:\", X_test_normalized.shape)\n","\n"]},{"cell_type":"code","source":["# asigno a una varaible nueva pasandole las variables normalizadas y las columnas\n","m_train, n_train = X_train_normalized.shape\n","m_test, n_test = X_test_normalized.shape\n","\n","X_train_norm = X_train_normalized\n","X_test_norm =X_test_normalized\n"],"metadata":{"id":"UT3Uk5OPcWrt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Conjunto de entrenamiento normalizado:\")\n","print(X_train_norm)\n","print(\"Conjunto de prueba normalizado:\")\n","print(X_test_norm)\n"],"metadata":{"id":"r9e6MRrW1G22","executionInfo":{"status":"ok","timestamp":1710770373717,"user_tz":240,"elapsed":33,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4ff83d3-2919-4651-eac5-c0fde73648b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Conjunto de entrenamiento normalizado:\n","[[ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," ...\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]]\n","Conjunto de prueba normalizado:\n","[[ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," ...\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]\n"," [ 0.         -0.00422581 -0.00795217 ...  0.          0.\n","   0.        ]]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5marXeKSxgM"},"outputs":[],"source":["# Selecciona aleatoriamente 100 puntos de datos para mostrar\n","# y la guardare el sel\n","rand_indices = np.random.choice(m, 100, replace=False)\n","sel = X[rand_indices, :]\n","\n","# displayData(sel)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sB9Kyi8SxgN"},"outputs":[],"source":["# usare la sigmoide ´para  tomar un valor real como entrada y produce un valor en el rango de 0 a 1 como salida\n","def sigmoid(z):\n","\n","    return 1.0 / (1.0 + np.exp(-z))"]},{"cell_type":"code","source":["#Usare una función de costo y su gradiente para un problema de regresión logística regularizada.\n","#para encontrar los parámetros theta que minimizan la función de costo.\n","\n","def lrCostFunction(theta, X, y, lambda_):\n","\n","    m = y.size\n","\n","    # convierte las etiquetas a valores enteros si son boleanos\n","    if y.dtype == bool:\n","        y = y.astype(int)\n","\n","    J = 0\n","    grad = np.zeros(theta.shape)\n","\n","    h = sigmoid(X.dot(theta.T))\n","\n","    temp = theta\n","    temp[0] = 0\n","\n","#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n","    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","\n","    grad = (1 / m) * (h - y).dot(X)\n","#     theta = theta - (alpha / m) * (h - y).dot(X)\n","    grad = grad + (lambda_ / m) * temp\n","\n","    return J, grad\n","#    return J, theta"],"metadata":{"id":"xUtIa6eauTfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# un ejemplo de calculo del costo\n","theta_initial = np.zeros(X_train_normalized.shape[1])\n","\n","# Definir el valor de lambda\n","lambda_ = 0.1\n","\n","# Calcular el costo y el gradiente utilizando la función de costo\n","costo, _ = lrCostFunction(theta_initial, X_train_normalized, y_train, lambda_)\n","\n","print(\"Costo de entrenamiento:\", costo)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcZCsvuVvIsV","executionInfo":{"status":"ok","timestamp":1710770373720,"user_tz":240,"elapsed":26,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"62f3dc6a-4bb2-4c41-d6d3-f0b2226c9d59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Costo de entrenamiento: 0.6931471805599532\n"]}]},{"cell_type":"code","source":["#usare scipy  para utilizar sus funcionalidades de optimización numérica en Python.\n","#entrenare con  \"One-vs-All\",para que me devuelba loss parámetros óptimos del modelo para cada clase.\n","from scipy import optimize\n","\n","def oneVsAll(X, y, num_labels, lambda_):\n","    # Algunas variables útiles\n","    m, n = X.shape\n","\n","    # Inicializar matriz de parámetros theta\n","    all_theta = np.zeros((num_labels, n + 1))\n","\n","    # Agregar una columna de unos a la matriz X\n","    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","\n","    # Optimizar los parámetros theta para cada clase\n","    for c in range(num_labels):\n","        initial_theta = np.zeros(n + 1)\n","        options = {'maxiter': 50}  # Opciones para el optimizador\n","        # Minimizar la función de costo regularizada utilizando el método de conjugado de gradiente\n","        res = optimize.minimize(lrCostFunction, initial_theta, (X, (y == c), lambda_), jac=True, method='CG', options=options)\n","        # Asignar los parámetros theta óptimos a la fila correspondiente en all_theta\n","        all_theta[c] = res.x\n","\n","    return all_theta\n"],"metadata":{"id":"ESFGf8QmvhrN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#entreno un clasificador usando uno vs todos e imprimo mis valores de mis clases\n","\n","lambda_ = 0.1\n","all_theta = oneVsAll(X, y, num_labels, lambda_)\n","print(all_theta.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h07m4RqrwkXY","executionInfo":{"status":"ok","timestamp":1710770470802,"user_tz":240,"elapsed":97100,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"cc0e84da-aa4c-4613-a43e-8b5b812b084a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-11-2a005c03c3ca>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-10-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-11-2a005c03c3ca>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-10-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-11-2a005c03c3ca>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-10-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-11-2a005c03c3ca>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","<ipython-input-10-325fe13cf96f>:4: RuntimeWarning: overflow encountered in exp\n","  return 1.0 / (1.0 + np.exp(-z))\n","<ipython-input-11-2a005c03c3ca>:21: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n"]},{"output_type":"stream","name":"stdout","text":["(10, 785)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjFoFe1bSxgO"},"outputs":[],"source":["#tomare los valores óptimos del modelo (all_theta) y un conjunto de datos de entrada (X), y\n","#predice las etiquetas de clase para cada muestra en X utilizando el enfoque de \"One-vs-All\" en la regresión logística\n","\n","def predictOneVsAll(all_theta, X):\n","\n","    m = X.shape[0];\n","    num_labels = all_theta.shape[0]\n","\n","    p = np.zeros(m)\n","\n","    # Add ones to the X data matrix\n","    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n","\n","    return p"]},{"cell_type":"code","source":["# Usando mi 20% de datos de prueba\n","print(X_test_norm.shape)\n","\n","# realizare  predicciones en el conjunto de prueba usando el 20%\n","pred_test = predictOneVsAll(all_theta, X_test_norm)\n","\n","#  la precisión en el conjunto de prueba usando mi 20% de y   de prueba\n","accuracy_test = np.mean(pred_test == y_test) * 100\n","\n","# Imprimir la precisión del conjunto de prueba\n","print('Precisión en el conjunto de prueba: {:.2f}%'.format(accuracy_test))\n","\n","# al igual que el ejemplo del ing seleccionare un subconjunto de datos de prueba para mostrar un ejemplo\n","X_prueba_subconjunto = X_test_norm[10:150, :]\n","y_prueba_subconjunto = y_test[10:150]\n","\n","# hoara agregare una columna de unos a la matriz X_prueba_subconjunto para realizar mis prediccion\n","X_prueba_subconjunto = np.concatenate([np.ones((X_prueba_subconjunto.shape[0], 1)), X_prueba_subconjunto], axis=1)\n","\n","# realizando las predicciones en el subconjunto de datos de prueba\n","pred_prueba_subconjunto = np.argmax(sigmoid(X_prueba_subconjunto.dot(all_theta.T)), axis=1)\n","\n","# Imprimo las predicciones y las etiquetas del mis 20% de datos de prueba aver si sale bien :V\n","print(\"Predicciones del subconjunto de datos de prueba:\")\n","print(pred_prueba_subconjunto)\n","print(\"Etiquetas reales del subconjunto de datos de prueba:\")\n","print(y_prueba_subconjunto)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKROnowsyyyU","executionInfo":{"status":"ok","timestamp":1710770470804,"user_tz":240,"elapsed":57,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"66e403a0-bff8-4f31-abfe-61dd719659cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(42000, 784)\n","Precisión en el conjunto de prueba: 72.13%\n","Predicciones del subconjunto de datos de prueba:\n","[2 9 7 3 0 0 4 0 4 3 4 7 7 6 7 1 0 7 4 7 1 6 4 0 7 3 3 1 7 6 7 1 6 2 7 2 9\n"," 0 3 9 2 4 1 1 3 3 2 3 0 4 6 1 4 9 1 1 9 0 1 1 0 6 5 1 6 6 3 9 0 1 1 6 1 3\n"," 3 0 1 4 2 0 6 0 7 6 0 2 4 9 7 1 9 1 2 0 0 7 1 1 3 7 1 7 1 1 7 7 0 4 2 6 1\n"," 3 9 7 1 0 9 3 1 7 7 0 9 4 1 9 9 2 6 2 9 0 4 3 7 3 7 4 1 2]\n","Etiquetas reales del subconjunto de datos de prueba:\n","[3. 9. 7. 2. 0. 0. 5. 0. 5. 5. 4. 7. 7. 6. 7. 1. 0. 7. 4. 7. 5. 6. 4. 0.\n"," 7. 5. 3. 8. 9. 4. 9. 8. 6. 2. 7. 2. 9. 0. 3. 9. 2. 5. 1. 1. 3. 9. 2. 3.\n"," 0. 4. 6. 1. 4. 9. 5. 1. 9. 0. 8. 1. 5. 6. 8. 1. 6. 6. 3. 9. 8. 1. 1. 6.\n"," 1. 3. 3. 0. 1. 4. 2. 0. 6. 0. 7. 2. 0. 2. 5. 9. 7. 1. 9. 1. 2. 8. 0. 9.\n"," 1. 8. 3. 7. 8. 7. 8. 3. 7. 7. 0. 4. 2. 8. 8. 3. 9. 7. 1. 5. 9. 3. 1. 9.\n"," 7. 5. 9. 4. 8. 9. 9. 2. 6. 2. 9. 5. 4. 3. 7. 3. 7. 4. 1. 2.]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WaT8luNSxgO"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}