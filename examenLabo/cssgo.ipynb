{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNP5v7BUcJm1pL5AZzylAz4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1OJzF8UGdjS7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713751442460,"user_tz":240,"elapsed":5395,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"b85ec7a5-bb82-42ba-f1d2-f7a10945c9a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from matplotlib import pyplot\n","from scipy import optimize\n","%matplotlib inline"],"metadata":{"id":"Z9l-ZJ2-dvVs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importar las bibliotecas necesarias\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","\n","# Cargar el conjunto de datos usando pandas\n","df = pd.read_csv('/content/drive/MyDrive/Red Neuronal/csgo_round_pepaed1.csv', delimiter=';')\n","\n","# Reemplazar los valores de 'round_winner' por 0 para \"CT\" y 1 para \"T\"\n","df['round_winner'] = df['round_winner'].map({'CT': 0, 'T': 1})\n","\n","# Dividir los datos en características (X) y etiquetas (y)\n","X = df.iloc[:, :-1].values  # Todas las columnas excepto la última (características)\n","y = df.iloc[:, -1].values   # La última columna (etiquetas)\n","\n","# Declarando variables para la división de datos (80% para entrenamiento, 20% para pruebas)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Normalizar características\n","def normalizarCaracteristicas(X_train, X_test):\n","    mu_train = np.mean(X_train, axis=0)\n","    sigma_train = np.std(X_train, axis=0)\n","\n","    sigma_train[sigma_train == 0] = 1e-10\n","\n","    X_train_norm = (X_train - mu_train) / sigma_train\n","    X_test_norm = (X_test - mu_train) / sigma_train\n","\n","    return X_train_norm, X_test_norm\n","\n","X_train, X_test = normalizarCaracteristicas(X_train, X_test)\n","\n","# Definir el modelo\n","model = Sequential() #Crea un modelo de red neuronal secuencial vacío.\n","model.add(Dense(50, input_shape=(X_train.shape[1],), activation='relu')) #capa densa de 50 neuronas y relu para la salida de una neurona menor o igal a cero no activado\n","#model.add(Dense(32, activation='relu'))  # Nueva capa oculta con 32 neuronas y activación ReLU\n","model.add(Dense(1, activation='sigmoid')) #capa de salida con 1 neuona para sber si o no\n","\n","# Compilar el modelo\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])#accurray predicciones corectas adam ajusta los pesos\n","\n","# Entrenar el modelo\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=2, validation_split=0.2) #numeo de entenamiento epoch\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"stD8W1TKd0Ya","executionInfo":{"status":"ok","timestamp":1713752247800,"user_tz":240,"elapsed":805350,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"bd17e6c1-a1f0-42ce-a475-8aa07ed84df0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","2449/2449 - 7s - loss: 0.4735 - accuracy: 0.7430 - val_loss: 0.4573 - val_accuracy: 0.7544 - 7s/epoch - 3ms/step\n","Epoch 2/150\n","2449/2449 - 5s - loss: 0.4525 - accuracy: 0.7554 - val_loss: 0.4526 - val_accuracy: 0.7550 - 5s/epoch - 2ms/step\n","Epoch 3/150\n","2449/2449 - 5s - loss: 0.4453 - accuracy: 0.7602 - val_loss: 0.4504 - val_accuracy: 0.7556 - 5s/epoch - 2ms/step\n","Epoch 4/150\n","2449/2449 - 5s - loss: 0.4399 - accuracy: 0.7655 - val_loss: 0.4474 - val_accuracy: 0.7592 - 5s/epoch - 2ms/step\n","Epoch 5/150\n","2449/2449 - 6s - loss: 0.4356 - accuracy: 0.7698 - val_loss: 0.4471 - val_accuracy: 0.7581 - 6s/epoch - 2ms/step\n","Epoch 6/150\n","2449/2449 - 5s - loss: 0.4320 - accuracy: 0.7722 - val_loss: 0.4449 - val_accuracy: 0.7593 - 5s/epoch - 2ms/step\n","Epoch 7/150\n","2449/2449 - 5s - loss: 0.4292 - accuracy: 0.7754 - val_loss: 0.4419 - val_accuracy: 0.7646 - 5s/epoch - 2ms/step\n","Epoch 8/150\n","2449/2449 - 6s - loss: 0.4261 - accuracy: 0.7784 - val_loss: 0.4444 - val_accuracy: 0.7618 - 6s/epoch - 3ms/step\n","Epoch 9/150\n","2449/2449 - 4s - loss: 0.4233 - accuracy: 0.7794 - val_loss: 0.4447 - val_accuracy: 0.7630 - 4s/epoch - 2ms/step\n","Epoch 10/150\n","2449/2449 - 5s - loss: 0.4213 - accuracy: 0.7800 - val_loss: 0.4403 - val_accuracy: 0.7649 - 5s/epoch - 2ms/step\n","Epoch 11/150\n","2449/2449 - 5s - loss: 0.4201 - accuracy: 0.7821 - val_loss: 0.4432 - val_accuracy: 0.7627 - 5s/epoch - 2ms/step\n","Epoch 12/150\n","2449/2449 - 5s - loss: 0.4179 - accuracy: 0.7845 - val_loss: 0.4451 - val_accuracy: 0.7635 - 5s/epoch - 2ms/step\n","Epoch 13/150\n","2449/2449 - 5s - loss: 0.4163 - accuracy: 0.7858 - val_loss: 0.4422 - val_accuracy: 0.7656 - 5s/epoch - 2ms/step\n","Epoch 14/150\n","2449/2449 - 5s - loss: 0.4138 - accuracy: 0.7876 - val_loss: 0.4446 - val_accuracy: 0.7647 - 5s/epoch - 2ms/step\n","Epoch 15/150\n","2449/2449 - 4s - loss: 0.4131 - accuracy: 0.7875 - val_loss: 0.4445 - val_accuracy: 0.7669 - 4s/epoch - 2ms/step\n","Epoch 16/150\n","2449/2449 - 6s - loss: 0.4115 - accuracy: 0.7885 - val_loss: 0.4414 - val_accuracy: 0.7672 - 6s/epoch - 3ms/step\n","Epoch 17/150\n","2449/2449 - 5s - loss: 0.4100 - accuracy: 0.7898 - val_loss: 0.4415 - val_accuracy: 0.7665 - 5s/epoch - 2ms/step\n","Epoch 18/150\n","2449/2449 - 5s - loss: 0.4092 - accuracy: 0.7911 - val_loss: 0.4400 - val_accuracy: 0.7675 - 5s/epoch - 2ms/step\n","Epoch 19/150\n","2449/2449 - 5s - loss: 0.4081 - accuracy: 0.7911 - val_loss: 0.4407 - val_accuracy: 0.7678 - 5s/epoch - 2ms/step\n","Epoch 20/150\n","2449/2449 - 5s - loss: 0.4062 - accuracy: 0.7940 - val_loss: 0.4409 - val_accuracy: 0.7678 - 5s/epoch - 2ms/step\n","Epoch 21/150\n","2449/2449 - 6s - loss: 0.4060 - accuracy: 0.7924 - val_loss: 0.4377 - val_accuracy: 0.7706 - 6s/epoch - 2ms/step\n","Epoch 22/150\n","2449/2449 - 5s - loss: 0.4046 - accuracy: 0.7930 - val_loss: 0.4424 - val_accuracy: 0.7672 - 5s/epoch - 2ms/step\n","Epoch 23/150\n","2449/2449 - 4s - loss: 0.4044 - accuracy: 0.7949 - val_loss: 0.4405 - val_accuracy: 0.7716 - 4s/epoch - 2ms/step\n","Epoch 24/150\n","2449/2449 - 6s - loss: 0.4030 - accuracy: 0.7947 - val_loss: 0.4403 - val_accuracy: 0.7693 - 6s/epoch - 3ms/step\n","Epoch 25/150\n","2449/2449 - 5s - loss: 0.4025 - accuracy: 0.7951 - val_loss: 0.4450 - val_accuracy: 0.7674 - 5s/epoch - 2ms/step\n","Epoch 26/150\n","2449/2449 - 5s - loss: 0.4015 - accuracy: 0.7959 - val_loss: 0.4420 - val_accuracy: 0.7681 - 5s/epoch - 2ms/step\n","Epoch 27/150\n","2449/2449 - 5s - loss: 0.4012 - accuracy: 0.7974 - val_loss: 0.4425 - val_accuracy: 0.7711 - 5s/epoch - 2ms/step\n","Epoch 28/150\n","2449/2449 - 5s - loss: 0.4002 - accuracy: 0.7971 - val_loss: 0.4395 - val_accuracy: 0.7731 - 5s/epoch - 2ms/step\n","Epoch 29/150\n","2449/2449 - 6s - loss: 0.3999 - accuracy: 0.7980 - val_loss: 0.4409 - val_accuracy: 0.7703 - 6s/epoch - 2ms/step\n","Epoch 30/150\n","2449/2449 - 4s - loss: 0.3994 - accuracy: 0.7993 - val_loss: 0.4383 - val_accuracy: 0.7739 - 4s/epoch - 2ms/step\n","Epoch 31/150\n","2449/2449 - 5s - loss: 0.3983 - accuracy: 0.7979 - val_loss: 0.4437 - val_accuracy: 0.7714 - 5s/epoch - 2ms/step\n","Epoch 32/150\n","2449/2449 - 7s - loss: 0.3978 - accuracy: 0.7996 - val_loss: 0.4451 - val_accuracy: 0.7704 - 7s/epoch - 3ms/step\n","Epoch 33/150\n","2449/2449 - 5s - loss: 0.3972 - accuracy: 0.8002 - val_loss: 0.4453 - val_accuracy: 0.7731 - 5s/epoch - 2ms/step\n","Epoch 34/150\n","2449/2449 - 6s - loss: 0.3973 - accuracy: 0.7994 - val_loss: 0.4416 - val_accuracy: 0.7734 - 6s/epoch - 2ms/step\n","Epoch 35/150\n","2449/2449 - 5s - loss: 0.3965 - accuracy: 0.8004 - val_loss: 0.4404 - val_accuracy: 0.7736 - 5s/epoch - 2ms/step\n","Epoch 36/150\n","2449/2449 - 4s - loss: 0.3955 - accuracy: 0.8001 - val_loss: 0.4393 - val_accuracy: 0.7768 - 4s/epoch - 2ms/step\n","Epoch 37/150\n","2449/2449 - 6s - loss: 0.3951 - accuracy: 0.8003 - val_loss: 0.4397 - val_accuracy: 0.7733 - 6s/epoch - 2ms/step\n","Epoch 38/150\n","2449/2449 - 5s - loss: 0.3945 - accuracy: 0.8009 - val_loss: 0.4428 - val_accuracy: 0.7733 - 5s/epoch - 2ms/step\n","Epoch 39/150\n","2449/2449 - 5s - loss: 0.3947 - accuracy: 0.8009 - val_loss: 0.4430 - val_accuracy: 0.7734 - 5s/epoch - 2ms/step\n","Epoch 40/150\n","2449/2449 - 6s - loss: 0.3940 - accuracy: 0.8015 - val_loss: 0.4453 - val_accuracy: 0.7733 - 6s/epoch - 2ms/step\n","Epoch 41/150\n","2449/2449 - 5s - loss: 0.3935 - accuracy: 0.8025 - val_loss: 0.4429 - val_accuracy: 0.7739 - 5s/epoch - 2ms/step\n","Epoch 42/150\n","2449/2449 - 6s - loss: 0.3929 - accuracy: 0.8022 - val_loss: 0.4472 - val_accuracy: 0.7730 - 6s/epoch - 2ms/step\n","Epoch 43/150\n","2449/2449 - 5s - loss: 0.3930 - accuracy: 0.8026 - val_loss: 0.4422 - val_accuracy: 0.7739 - 5s/epoch - 2ms/step\n","Epoch 44/150\n","2449/2449 - 5s - loss: 0.3924 - accuracy: 0.8016 - val_loss: 0.4356 - val_accuracy: 0.7768 - 5s/epoch - 2ms/step\n","Epoch 45/150\n","2449/2449 - 6s - loss: 0.3916 - accuracy: 0.8028 - val_loss: 0.4418 - val_accuracy: 0.7781 - 6s/epoch - 2ms/step\n","Epoch 46/150\n","2449/2449 - 5s - loss: 0.3910 - accuracy: 0.8029 - val_loss: 0.4422 - val_accuracy: 0.7773 - 5s/epoch - 2ms/step\n","Epoch 47/150\n","2449/2449 - 5s - loss: 0.3910 - accuracy: 0.8034 - val_loss: 0.4417 - val_accuracy: 0.7759 - 5s/epoch - 2ms/step\n","Epoch 48/150\n","2449/2449 - 6s - loss: 0.3911 - accuracy: 0.8033 - val_loss: 0.4430 - val_accuracy: 0.7770 - 6s/epoch - 2ms/step\n","Epoch 49/150\n","2449/2449 - 5s - loss: 0.3901 - accuracy: 0.8041 - val_loss: 0.4470 - val_accuracy: 0.7732 - 5s/epoch - 2ms/step\n","Epoch 50/150\n","2449/2449 - 6s - loss: 0.3899 - accuracy: 0.8055 - val_loss: 0.4428 - val_accuracy: 0.7771 - 6s/epoch - 2ms/step\n","Epoch 51/150\n","2449/2449 - 4s - loss: 0.3899 - accuracy: 0.8036 - val_loss: 0.4423 - val_accuracy: 0.7772 - 4s/epoch - 2ms/step\n","Epoch 52/150\n","2449/2449 - 4s - loss: 0.3889 - accuracy: 0.8055 - val_loss: 0.4453 - val_accuracy: 0.7748 - 4s/epoch - 2ms/step\n","Epoch 53/150\n","2449/2449 - 6s - loss: 0.3888 - accuracy: 0.8050 - val_loss: 0.4461 - val_accuracy: 0.7770 - 6s/epoch - 3ms/step\n","Epoch 54/150\n","2449/2449 - 5s - loss: 0.3882 - accuracy: 0.8051 - val_loss: 0.4440 - val_accuracy: 0.7772 - 5s/epoch - 2ms/step\n","Epoch 55/150\n","2449/2449 - 5s - loss: 0.3881 - accuracy: 0.8059 - val_loss: 0.4436 - val_accuracy: 0.7769 - 5s/epoch - 2ms/step\n","Epoch 56/150\n","2449/2449 - 6s - loss: 0.3883 - accuracy: 0.8059 - val_loss: 0.4445 - val_accuracy: 0.7780 - 6s/epoch - 2ms/step\n","Epoch 57/150\n","2449/2449 - 4s - loss: 0.3880 - accuracy: 0.8046 - val_loss: 0.4420 - val_accuracy: 0.7765 - 4s/epoch - 2ms/step\n","Epoch 58/150\n","2449/2449 - 6s - loss: 0.3869 - accuracy: 0.8055 - val_loss: 0.4444 - val_accuracy: 0.7777 - 6s/epoch - 2ms/step\n","Epoch 59/150\n","2449/2449 - 5s - loss: 0.3869 - accuracy: 0.8057 - val_loss: 0.4423 - val_accuracy: 0.7777 - 5s/epoch - 2ms/step\n","Epoch 60/150\n","2449/2449 - 5s - loss: 0.3867 - accuracy: 0.8071 - val_loss: 0.4415 - val_accuracy: 0.7792 - 5s/epoch - 2ms/step\n","Epoch 61/150\n","2449/2449 - 6s - loss: 0.3864 - accuracy: 0.8071 - val_loss: 0.4403 - val_accuracy: 0.7782 - 6s/epoch - 3ms/step\n","Epoch 62/150\n","2449/2449 - 4s - loss: 0.3861 - accuracy: 0.8061 - val_loss: 0.4432 - val_accuracy: 0.7749 - 4s/epoch - 2ms/step\n","Epoch 63/150\n","2449/2449 - 5s - loss: 0.3855 - accuracy: 0.8080 - val_loss: 0.4428 - val_accuracy: 0.7777 - 5s/epoch - 2ms/step\n","Epoch 64/150\n","2449/2449 - 5s - loss: 0.3862 - accuracy: 0.8062 - val_loss: 0.4429 - val_accuracy: 0.7779 - 5s/epoch - 2ms/step\n","Epoch 65/150\n","2449/2449 - 5s - loss: 0.3851 - accuracy: 0.8071 - val_loss: 0.4430 - val_accuracy: 0.7764 - 5s/epoch - 2ms/step\n","Epoch 66/150\n","2449/2449 - 6s - loss: 0.3848 - accuracy: 0.8072 - val_loss: 0.4432 - val_accuracy: 0.7765 - 6s/epoch - 3ms/step\n","Epoch 67/150\n","2449/2449 - 4s - loss: 0.3850 - accuracy: 0.8083 - val_loss: 0.4445 - val_accuracy: 0.7779 - 4s/epoch - 2ms/step\n","Epoch 68/150\n","2449/2449 - 5s - loss: 0.3848 - accuracy: 0.8076 - val_loss: 0.4430 - val_accuracy: 0.7777 - 5s/epoch - 2ms/step\n","Epoch 69/150\n","2449/2449 - 6s - loss: 0.3846 - accuracy: 0.8077 - val_loss: 0.4459 - val_accuracy: 0.7797 - 6s/epoch - 2ms/step\n","Epoch 70/150\n","2449/2449 - 4s - loss: 0.3846 - accuracy: 0.8085 - val_loss: 0.4408 - val_accuracy: 0.7794 - 4s/epoch - 2ms/step\n","Epoch 71/150\n","2449/2449 - 6s - loss: 0.3836 - accuracy: 0.8072 - val_loss: 0.4420 - val_accuracy: 0.7766 - 6s/epoch - 2ms/step\n","Epoch 72/150\n","2449/2449 - 6s - loss: 0.3839 - accuracy: 0.8077 - val_loss: 0.4410 - val_accuracy: 0.7799 - 6s/epoch - 2ms/step\n","Epoch 73/150\n","2449/2449 - 5s - loss: 0.3833 - accuracy: 0.8076 - val_loss: 0.4421 - val_accuracy: 0.7775 - 5s/epoch - 2ms/step\n","Epoch 74/150\n","2449/2449 - 6s - loss: 0.3834 - accuracy: 0.8088 - val_loss: 0.4384 - val_accuracy: 0.7800 - 6s/epoch - 3ms/step\n","Epoch 75/150\n","2449/2449 - 5s - loss: 0.3833 - accuracy: 0.8071 - val_loss: 0.4432 - val_accuracy: 0.7760 - 5s/epoch - 2ms/step\n","Epoch 76/150\n","2449/2449 - 5s - loss: 0.3834 - accuracy: 0.8088 - val_loss: 0.4396 - val_accuracy: 0.7768 - 5s/epoch - 2ms/step\n","Epoch 77/150\n","2449/2449 - 5s - loss: 0.3828 - accuracy: 0.8079 - val_loss: 0.4431 - val_accuracy: 0.7785 - 5s/epoch - 2ms/step\n","Epoch 78/150\n","2449/2449 - 5s - loss: 0.3829 - accuracy: 0.8085 - val_loss: 0.4402 - val_accuracy: 0.7784 - 5s/epoch - 2ms/step\n","Epoch 79/150\n","2449/2449 - 6s - loss: 0.3822 - accuracy: 0.8080 - val_loss: 0.4450 - val_accuracy: 0.7767 - 6s/epoch - 2ms/step\n","Epoch 80/150\n","2449/2449 - 5s - loss: 0.3819 - accuracy: 0.8097 - val_loss: 0.4401 - val_accuracy: 0.7818 - 5s/epoch - 2ms/step\n","Epoch 81/150\n","2449/2449 - 5s - loss: 0.3815 - accuracy: 0.8092 - val_loss: 0.4400 - val_accuracy: 0.7792 - 5s/epoch - 2ms/step\n","Epoch 82/150\n","2449/2449 - 5s - loss: 0.3816 - accuracy: 0.8091 - val_loss: 0.4408 - val_accuracy: 0.7792 - 5s/epoch - 2ms/step\n","Epoch 83/150\n","2449/2449 - 5s - loss: 0.3822 - accuracy: 0.8091 - val_loss: 0.4387 - val_accuracy: 0.7785 - 5s/epoch - 2ms/step\n","Epoch 84/150\n","2449/2449 - 6s - loss: 0.3816 - accuracy: 0.8097 - val_loss: 0.4412 - val_accuracy: 0.7782 - 6s/epoch - 2ms/step\n","Epoch 85/150\n","2449/2449 - 5s - loss: 0.3811 - accuracy: 0.8093 - val_loss: 0.4370 - val_accuracy: 0.7797 - 5s/epoch - 2ms/step\n","Epoch 86/150\n","2449/2449 - 4s - loss: 0.3806 - accuracy: 0.8103 - val_loss: 0.4400 - val_accuracy: 0.7794 - 4s/epoch - 2ms/step\n","Epoch 87/150\n","2449/2449 - 6s - loss: 0.3812 - accuracy: 0.8099 - val_loss: 0.4418 - val_accuracy: 0.7795 - 6s/epoch - 2ms/step\n","Epoch 88/150\n","2449/2449 - 5s - loss: 0.3810 - accuracy: 0.8092 - val_loss: 0.4367 - val_accuracy: 0.7816 - 5s/epoch - 2ms/step\n","Epoch 89/150\n","2449/2449 - 4s - loss: 0.3800 - accuracy: 0.8103 - val_loss: 0.4458 - val_accuracy: 0.7796 - 4s/epoch - 2ms/step\n","Epoch 90/150\n","2449/2449 - 6s - loss: 0.3806 - accuracy: 0.8096 - val_loss: 0.4496 - val_accuracy: 0.7760 - 6s/epoch - 2ms/step\n","Epoch 91/150\n","2449/2449 - 5s - loss: 0.3799 - accuracy: 0.8112 - val_loss: 0.4456 - val_accuracy: 0.7756 - 5s/epoch - 2ms/step\n","Epoch 92/150\n","2449/2449 - 5s - loss: 0.3799 - accuracy: 0.8093 - val_loss: 0.4436 - val_accuracy: 0.7781 - 5s/epoch - 2ms/step\n","Epoch 93/150\n","2449/2449 - 5s - loss: 0.3802 - accuracy: 0.8106 - val_loss: 0.4447 - val_accuracy: 0.7771 - 5s/epoch - 2ms/step\n","Epoch 94/150\n","2449/2449 - 5s - loss: 0.3794 - accuracy: 0.8098 - val_loss: 0.4492 - val_accuracy: 0.7746 - 5s/epoch - 2ms/step\n","Epoch 95/150\n","2449/2449 - 6s - loss: 0.3795 - accuracy: 0.8109 - val_loss: 0.4498 - val_accuracy: 0.7751 - 6s/epoch - 2ms/step\n","Epoch 96/150\n","2449/2449 - 5s - loss: 0.3798 - accuracy: 0.8103 - val_loss: 0.4427 - val_accuracy: 0.7776 - 5s/epoch - 2ms/step\n","Epoch 97/150\n","2449/2449 - 5s - loss: 0.3789 - accuracy: 0.8104 - val_loss: 0.4480 - val_accuracy: 0.7768 - 5s/epoch - 2ms/step\n","Epoch 98/150\n","2449/2449 - 6s - loss: 0.3795 - accuracy: 0.8113 - val_loss: 0.4468 - val_accuracy: 0.7801 - 6s/epoch - 2ms/step\n","Epoch 99/150\n","2449/2449 - 5s - loss: 0.3786 - accuracy: 0.8119 - val_loss: 0.4457 - val_accuracy: 0.7791 - 5s/epoch - 2ms/step\n","Epoch 100/150\n","2449/2449 - 6s - loss: 0.3786 - accuracy: 0.8113 - val_loss: 0.4448 - val_accuracy: 0.7795 - 6s/epoch - 2ms/step\n","Epoch 101/150\n","2449/2449 - 5s - loss: 0.3787 - accuracy: 0.8108 - val_loss: 0.4436 - val_accuracy: 0.7775 - 5s/epoch - 2ms/step\n","Epoch 102/150\n","2449/2449 - 5s - loss: 0.3792 - accuracy: 0.8103 - val_loss: 0.4409 - val_accuracy: 0.7793 - 5s/epoch - 2ms/step\n","Epoch 103/150\n","2449/2449 - 6s - loss: 0.3786 - accuracy: 0.8120 - val_loss: 0.4446 - val_accuracy: 0.7789 - 6s/epoch - 2ms/step\n","Epoch 104/150\n","2449/2449 - 5s - loss: 0.3785 - accuracy: 0.8102 - val_loss: 0.4405 - val_accuracy: 0.7807 - 5s/epoch - 2ms/step\n","Epoch 105/150\n","2449/2449 - 5s - loss: 0.3782 - accuracy: 0.8105 - val_loss: 0.4394 - val_accuracy: 0.7791 - 5s/epoch - 2ms/step\n","Epoch 106/150\n","2449/2449 - 5s - loss: 0.3779 - accuracy: 0.8121 - val_loss: 0.4426 - val_accuracy: 0.7779 - 5s/epoch - 2ms/step\n","Epoch 107/150\n","2449/2449 - 5s - loss: 0.3782 - accuracy: 0.8111 - val_loss: 0.4373 - val_accuracy: 0.7788 - 5s/epoch - 2ms/step\n","Epoch 108/150\n","2449/2449 - 6s - loss: 0.3778 - accuracy: 0.8119 - val_loss: 0.4435 - val_accuracy: 0.7764 - 6s/epoch - 3ms/step\n","Epoch 109/150\n","2449/2449 - 5s - loss: 0.3780 - accuracy: 0.8112 - val_loss: 0.4444 - val_accuracy: 0.7786 - 5s/epoch - 2ms/step\n","Epoch 110/150\n","2449/2449 - 5s - loss: 0.3774 - accuracy: 0.8120 - val_loss: 0.4464 - val_accuracy: 0.7741 - 5s/epoch - 2ms/step\n","Epoch 111/150\n","2449/2449 - 5s - loss: 0.3770 - accuracy: 0.8125 - val_loss: 0.4387 - val_accuracy: 0.7795 - 5s/epoch - 2ms/step\n","Epoch 112/150\n","2449/2449 - 5s - loss: 0.3771 - accuracy: 0.8124 - val_loss: 0.4401 - val_accuracy: 0.7781 - 5s/epoch - 2ms/step\n","Epoch 113/150\n","2449/2449 - 6s - loss: 0.3773 - accuracy: 0.8124 - val_loss: 0.4437 - val_accuracy: 0.7791 - 6s/epoch - 2ms/step\n","Epoch 114/150\n","2449/2449 - 5s - loss: 0.3774 - accuracy: 0.8122 - val_loss: 0.4426 - val_accuracy: 0.7785 - 5s/epoch - 2ms/step\n","Epoch 115/150\n","2449/2449 - 5s - loss: 0.3766 - accuracy: 0.8121 - val_loss: 0.4499 - val_accuracy: 0.7789 - 5s/epoch - 2ms/step\n","Epoch 116/150\n","2449/2449 - 6s - loss: 0.3769 - accuracy: 0.8120 - val_loss: 0.4465 - val_accuracy: 0.7801 - 6s/epoch - 2ms/step\n","Epoch 117/150\n","2449/2449 - 5s - loss: 0.3761 - accuracy: 0.8135 - val_loss: 0.4471 - val_accuracy: 0.7801 - 5s/epoch - 2ms/step\n","Epoch 118/150\n","2449/2449 - 5s - loss: 0.3766 - accuracy: 0.8129 - val_loss: 0.4467 - val_accuracy: 0.7745 - 5s/epoch - 2ms/step\n","Epoch 119/150\n","2449/2449 - 5s - loss: 0.3770 - accuracy: 0.8124 - val_loss: 0.4415 - val_accuracy: 0.7760 - 5s/epoch - 2ms/step\n","Epoch 120/150\n","2449/2449 - 5s - loss: 0.3765 - accuracy: 0.8129 - val_loss: 0.4396 - val_accuracy: 0.7819 - 5s/epoch - 2ms/step\n","Epoch 121/150\n","2449/2449 - 6s - loss: 0.3764 - accuracy: 0.8135 - val_loss: 0.4419 - val_accuracy: 0.7755 - 6s/epoch - 2ms/step\n","Epoch 122/150\n","2449/2449 - 5s - loss: 0.3758 - accuracy: 0.8129 - val_loss: 0.4437 - val_accuracy: 0.7784 - 5s/epoch - 2ms/step\n","Epoch 123/150\n","2449/2449 - 5s - loss: 0.3765 - accuracy: 0.8126 - val_loss: 0.4456 - val_accuracy: 0.7775 - 5s/epoch - 2ms/step\n","Epoch 124/150\n","2449/2449 - 6s - loss: 0.3759 - accuracy: 0.8135 - val_loss: 0.4433 - val_accuracy: 0.7784 - 6s/epoch - 2ms/step\n","Epoch 125/150\n","2449/2449 - 4s - loss: 0.3755 - accuracy: 0.8137 - val_loss: 0.4431 - val_accuracy: 0.7780 - 4s/epoch - 2ms/step\n","Epoch 126/150\n","2449/2449 - 5s - loss: 0.3758 - accuracy: 0.8131 - val_loss: 0.4409 - val_accuracy: 0.7805 - 5s/epoch - 2ms/step\n","Epoch 127/150\n","2449/2449 - 6s - loss: 0.3753 - accuracy: 0.8134 - val_loss: 0.4418 - val_accuracy: 0.7775 - 6s/epoch - 2ms/step\n","Epoch 128/150\n","2449/2449 - 5s - loss: 0.3752 - accuracy: 0.8140 - val_loss: 0.4439 - val_accuracy: 0.7797 - 5s/epoch - 2ms/step\n","Epoch 129/150\n","2449/2449 - 6s - loss: 0.3753 - accuracy: 0.8131 - val_loss: 0.4423 - val_accuracy: 0.7794 - 6s/epoch - 2ms/step\n","Epoch 130/150\n","2449/2449 - 5s - loss: 0.3756 - accuracy: 0.8134 - val_loss: 0.4410 - val_accuracy: 0.7803 - 5s/epoch - 2ms/step\n","Epoch 131/150\n","2449/2449 - 5s - loss: 0.3753 - accuracy: 0.8129 - val_loss: 0.4381 - val_accuracy: 0.7815 - 5s/epoch - 2ms/step\n","Epoch 132/150\n","2449/2449 - 6s - loss: 0.3752 - accuracy: 0.8134 - val_loss: 0.4399 - val_accuracy: 0.7759 - 6s/epoch - 3ms/step\n","Epoch 133/150\n","2449/2449 - 4s - loss: 0.3745 - accuracy: 0.8137 - val_loss: 0.4451 - val_accuracy: 0.7761 - 4s/epoch - 2ms/step\n","Epoch 134/150\n","2449/2449 - 5s - loss: 0.3749 - accuracy: 0.8136 - val_loss: 0.4406 - val_accuracy: 0.7790 - 5s/epoch - 2ms/step\n","Epoch 135/150\n","2449/2449 - 5s - loss: 0.3749 - accuracy: 0.8145 - val_loss: 0.4406 - val_accuracy: 0.7811 - 5s/epoch - 2ms/step\n","Epoch 136/150\n","2449/2449 - 5s - loss: 0.3748 - accuracy: 0.8140 - val_loss: 0.4422 - val_accuracy: 0.7772 - 5s/epoch - 2ms/step\n","Epoch 137/150\n","2449/2449 - 6s - loss: 0.3747 - accuracy: 0.8137 - val_loss: 0.4424 - val_accuracy: 0.7797 - 6s/epoch - 2ms/step\n","Epoch 138/150\n","2449/2449 - 4s - loss: 0.3743 - accuracy: 0.8148 - val_loss: 0.4371 - val_accuracy: 0.7807 - 4s/epoch - 2ms/step\n","Epoch 139/150\n","2449/2449 - 5s - loss: 0.3745 - accuracy: 0.8133 - val_loss: 0.4411 - val_accuracy: 0.7771 - 5s/epoch - 2ms/step\n","Epoch 140/150\n","2449/2449 - 6s - loss: 0.3738 - accuracy: 0.8138 - val_loss: 0.4430 - val_accuracy: 0.7792 - 6s/epoch - 2ms/step\n","Epoch 141/150\n","2449/2449 - 5s - loss: 0.3741 - accuracy: 0.8154 - val_loss: 0.4403 - val_accuracy: 0.7784 - 5s/epoch - 2ms/step\n","Epoch 142/150\n","2449/2449 - 5s - loss: 0.3743 - accuracy: 0.8145 - val_loss: 0.4396 - val_accuracy: 0.7763 - 5s/epoch - 2ms/step\n","Epoch 143/150\n","2449/2449 - 5s - loss: 0.3740 - accuracy: 0.8152 - val_loss: 0.4416 - val_accuracy: 0.7774 - 5s/epoch - 2ms/step\n","Epoch 144/150\n","2449/2449 - 4s - loss: 0.3734 - accuracy: 0.8151 - val_loss: 0.4404 - val_accuracy: 0.7780 - 4s/epoch - 2ms/step\n","Epoch 145/150\n","2449/2449 - 6s - loss: 0.3738 - accuracy: 0.8142 - val_loss: 0.4405 - val_accuracy: 0.7784 - 6s/epoch - 2ms/step\n","Epoch 146/150\n","2449/2449 - 5s - loss: 0.3733 - accuracy: 0.8144 - val_loss: 0.4423 - val_accuracy: 0.7811 - 5s/epoch - 2ms/step\n","Epoch 147/150\n","2449/2449 - 4s - loss: 0.3736 - accuracy: 0.8143 - val_loss: 0.4420 - val_accuracy: 0.7767 - 4s/epoch - 2ms/step\n","Epoch 148/150\n","2449/2449 - 6s - loss: 0.3736 - accuracy: 0.8146 - val_loss: 0.4435 - val_accuracy: 0.7780 - 6s/epoch - 2ms/step\n","Epoch 149/150\n","2449/2449 - 5s - loss: 0.3740 - accuracy: 0.8144 - val_loss: 0.4500 - val_accuracy: 0.7784 - 5s/epoch - 2ms/step\n","Epoch 150/150\n","2449/2449 - 5s - loss: 0.3729 - accuracy: 0.8165 - val_loss: 0.4577 - val_accuracy: 0.7733 - 5s/epoch - 2ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78e063b58160>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["print(\"Tamaño de datos de entrenamiento para X:\", X_train.shape)\n","print(\"Tamaño de datos de entrenamiento para y:\", y_train.shape)\n","\n","# Imprimir el tamaño de los datos de prueba\n","print(\"Tamaño de datos de prueba para X:\", X_test.shape)\n","print(\"Tamaño de datos de prueba para y:\", y_test.shape)\n","print(y)\n","print(df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mwXft7sYisjv","executionInfo":{"status":"ok","timestamp":1713752247802,"user_tz":240,"elapsed":42,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"a15a5499-3d04-4b00-c3c3-0e4d1cc4f4a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño de datos de entrenamiento para X: (97928, 94)\n","Tamaño de datos de entrenamiento para y: (97928,)\n","Tamaño de datos de prueba para X: (24482, 94)\n","Tamaño de datos de prueba para y: (24482,)\n","[0 0 0 ... 1 1 1]\n","(122410, 95)\n"]}]},{"cell_type":"code","source":["# Evaluar el modelo en los datos de prueba\n","#calculo de precison correctas  y perdida cuan serca estan de velores verdaderos\n","test_results = model.evaluate(X_test, y_test, verbose=1)\n","\n","# Imprimir los resultados de prueba\n","print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1] * 100}%')\n","# test_results Es el valor de la pérdida del modelo en los datos de prueba."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dt8iuITmiy7e","executionInfo":{"status":"ok","timestamp":1713752260997,"user_tz":240,"elapsed":1614,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"1664aebe-0ccd-4a9c-b5f2-3d11b6a2cfdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["766/766 [==============================] - 1s 2ms/step - loss: 0.4522 - accuracy: 0.7713\n","Test results - Loss: 0.45215311646461487 - Accuracy: 77.12604999542236%\n"]}]},{"cell_type":"code","source":["# Evaluar el modelo en los datos de prueba\n","scores = model.evaluate(X_test, y_test)\n","\n","# Imprimir la precisión del modelo\n","print(\"\\nAccuracy: %.2f%%\" % (scores[1] * 100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNzJtne-mR_g","executionInfo":{"status":"ok","timestamp":1713752341170,"user_tz":240,"elapsed":2501,"user":{"displayName":"Luis Andres Mamani Burgos","userId":"16600547215462432904"}},"outputId":"431708e1-a00b-4e94-bed9-f5ec4599af68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["766/766 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.7713\n","\n","Accuracy: 77.13%\n"]}]}]}